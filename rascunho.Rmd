---
title: "An"
author: "Doriedson"
date: "09-11-2024"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r include=FALSE}
require(ggplot2)
require(dplyr)
require(patchwork)

source('arquivo1.R')

library(lemon)
knit_print.data.frame <- lemon_print

```

## Os dados

Trata-se de um conjunto extenso, com mais de 20 mil observações e 680 variáveis, sobre receitas culinárias do site _Epicurious_. Houve uma filtragem inicial no conjunto, restaram apenas 6 variáveis explicativas, as consideradas mais importantes: nota, a quantidade de calorias, de proteína, de gordura e de sódio. Há também o nome da receita e a variável resposta, que no caso é binária: trata-se de uma sobremesa? No site em questão, encontra-se categorias de pratos como _café da manhã_, _almoço_, _jantar_, _drinks_ e, naturalmente, o objeto de interesse do trabalho, as _sobremesas_.

Em seguida, foi feita a exclusão de linhas que possuíam valores faltantes. Por fim, houve a retirada de valores absurdos (descrita mais detalhadamente abaixo). O conjunto final possui 15706 observações e 7 variáveis.

Obs.: a variável calorias está na unidade 'kcal'.

```{r}
dados = read.csv(Fonte)

#attach(dados)

dsel = cbind(dados[, c(1:6)], dados$dessert)

colnames(dsel)
colnames(dsel) <- c("titulo", "nota", "calorias", "proteina",
                    "gordura", "sodio", "sobremesa")
dsel <- na.omit(dsel)

attach(dsel)

head(dsel); dim(dsel)

```

Observando o percentil 99 tem-se que 99% dos valores são menores ou iguais a 3257 kcal. Tomarei como limite das observações de caloria, pois é improvável/inviável que receitas ultrapassem de maneira tão acentuada esse valor; receitas com milhões de kcal são claramente erros nessa base de dados. Foi feito um tratamento semelhante para a variável _sódio_.

```{r}
#quantile(dsel$calorias, seq(0, 1, .01))

# Retirando valores absurdos de calorias e sódio
dsel <- subset(dsel, dsel$calorias <= quantile(dsel$calorias, .99)[[1]] & 
                 dsel$sodio <= quantile(dsel$sodio, .98)[[1]])

dsel <- dsel %>% mutate(status = case_when(sobremesa == 1 ~ "positivo",
                          sobremesa == 0 ~ "negativo"))

sum(dsel$sobremesa)/length(dsel$sobremesa)

```

## Análise descritiva

Como visto no gráfico 'b', a variável nota não aparenta ser influenciada pelo tipo da receita.

```{r, fig.cap="Comportamento das receitas em relação à caloria"}
g_cal = ggplot(data = dsel, aes(x = calorias, y = status)) +
  geom_jitter(aes(col=factor(status)), alpha = .2) +
  labs(title = "b", color = "Sobremesa",
       y = "",
       x = "Calorias (kcal)") +
  scale_color_manual(values = c("navy", "red"),
                     labels = c("negativo", "positivo")) +
  ggthemes::theme_tufte() +
  theme(legend.position = 'none')

#{r, fig.cap="Comportamento das receitas em relação à nota"}
g_n = ggplot(data = dsel, aes(x = nota, y = status)) +
  geom_jitter(aes(col=factor(status)), alpha = .2) +
  labs(title = "c", color = "Sobremesa",
       y = "",
       x = "Nota") +
  scale_color_manual(values = c("navy", "red"),
                     labels = c("negativo", "positivo")) +
  scale_x_continuous(breaks = seq(0, 5, .5)) +
  ggthemes::theme_tufte() +
  theme(legend.position = 'none')

#{r, fig.cap="Comportamento das receitas em relação ao sódio"}
g_s = ggplot(data = dsel, aes(x = sodio, y = status)) +
  geom_jitter(aes(col=factor(status)), alpha = .2) +
  labs(title = "a", color = "Sobremesa",
       y = "É sobremesa?",
       x = "Sódio (mg)") +
  scale_color_manual(values = c("navy", "red"),
                     labels = c("negativo", "positivo")) +
    ggthemes::theme_tufte() +
  theme(legend.position = 'none')

#{r, fig.cap="Comportamento das receitas em relação à gordura"}
g_g = ggplot(data = dsel, aes(x = gordura, y = status)) +
  geom_jitter(aes(col=factor(status)), alpha = .2) +
  labs(title = "e", color = "Sobremesa",
       y = "",
       x = "Gordura (g)") +
  scale_color_manual(values = c("navy", "red"),
                     labels = c("negativo", "positivo")) +
  #ggthemes::theme_few()+
  ggthemes::theme_tufte() +
  theme(legend.position = 'none')

g_p = ggplot(data = dsel, aes(x = proteina, y = status)) +
  geom_jitter(aes(col=factor(status)), alpha = .2) +
  labs(title = "d", color = "Sobremesa",
       y = "",
       x = "Proteína (g)") +
  scale_color_manual(values = c("navy", "red"),
                     labels = c("negativo", "positivo")) +
  #ggthemes::theme_few()+
  ggthemes::theme_tufte() +
  theme(legend.position = 'none')

```

```{r}
library(patchwork)

g_s / (g_cal + g_n + g_p + g_g)

```

```{r}
#g_p
```


\newpage

## Modelo base

O modelo principal será analisado da seguinte maneira: o conjunto de dados selecionados será dividido em _conjunto_treino_ (70%) e _conjunto_teste_ (30%)


```{r LOGIT, warning=FALSE}
set.seed(2024)
# observações sorteadas (reordenadas)
aux1 = sample(c(1:length(dsel[, 1])))

df1_treino = dsel[aux1[1:(length(aux1)*.7)], ]
df1_teste = dsel[aux1[(length(aux1)*.7):length(aux1)], ]

# Verificando quantos nomes se repetem
#cont = 0 
#for(x in df1_teste$titulo){
#  if(x %in% df1_treino$titulo){cont = cont + 1}}

# f.lig. canonica
modelo = glm(sobremesa ~ nota + calorias + proteina + gordura + sodio,
             family = binomial(link = 'logit'), data = df1_treino)

summary(modelo)

preditos = predict(object = modelo, newdata = df1_teste, type = "response")

df1_teste$prob_pred <- preditos

```

```{r Precisa retirar variaveis}
MASS::stepAIC(modelo)

```


##### Teste com as outras funções de ligação.

```{r PROBIT}
modelo2 = glm(sobremesa ~ nota + calorias + proteina + gordura + sodio,
             family = binomial(link = 'probit'),
             data = df1_treino)

summary(modelo2)

```


```{r LOGLOG}
# O algoritmo não convergiu! 
modelo3 = glm(sobremesa ~ nota + calorias + proteina + gordura + sodio,
             family = binomial(link = 'cloglog'),
             data = df1_treino)

summary(modelo3)

```

```{r, warning=FALSE}
#hnp::hnp(modelo)
par(bg='gray')
hnp::hnp(modelo2, print.on = T, main="modelo 2")

hnp::hnp(modelo3, print.on = T, main="modelo 3")

```


```{r}
curva_roc = pROC::roc(df1_teste$sobremesa, df1_teste$prob_pred)
plot(curva_roc)
#pROC::auc(curva_roc)
optimal_coords <- pROC::coords(curva_roc, "best", ret = c("threshold",
                                                          "sensitivity",
                                                          "specificity"))

points(optimal_coords[3], optimal_coords[2], col = "red", pch = 19, cex = 1.5)

# Display optimal coordinates
optimal_coords$threshold
```

```{r}
confundir =  function(referencia, predito){
  # Os dois vetores binários precisam ter o mesmo tamanho, pois serão comparados
  
  df = data.frame('referencia'=referencia, 'predito'=predito)
  
  head(df)
  
  TP = dim(subset(df, df$referencia == 1 & df$predito == 1))[1]
  TN = dim(subset(df, df$referencia == 0 & df$predito == 0))[1]
  FP = dim(subset(df, df$referencia == 0 & df$predito == 1))[1]
  FN = dim(subset(df, df$referencia == 1 & df$predito == 0))[1]
  
  sens = TP/(TP + FN)
  espec = TN / (TN + FP)
  acuracia = (TP + TN) / (TP + TN + FP + FN)
  interesse = (TP + FN) / (TP + TN + FP + FN)
  precisao = TP / (TP + FP)


  dffinal = data.frame('Evento de interesse' = interesse,
                       'Sensibilidade' = sens, 'Especificidade'= espec,
                       'Acuracidade' = acuracia, 'Precisao' = precisao
                       )
  return(dffinal)
}

#x=confundir(df1_teste$sobremesa, df1_teste$predito)
```


```{r Resultados, echo=TRUE}
# tidymodels e tidyverse
df1_teste$predito <- ifelse(df1_teste$prob_pred < optimal_coords$threshold, 0, 1)

table(df1_teste$sobremesa)
table(df1_teste$predito)


# Para o gráfico apenas
conf.m = caret::confusionMatrix(data = as.factor(df1_teste$predito),
                         reference = as.factor(df1_teste$sobremesa))
df = as.data.frame(conf.m$table)

ggplot(df, aes(Prediction, Reference, fill=Freq)) +
  geom_tile() +
  geom_tile(colour = 'black') +
  ggthemes::theme_tufte() +
  theme(legend.position = 'none') +
  geom_text(aes(label = Freq)) + # write the values
  scale_fill_gradient2(low = scales::muted("white"),
                       high = scales::muted("midnightblue")) +
  labs(title = "Matriz de confusao", x="Predito", y = "Real")
```


```{r Resultados2, echo=TRUE}
confundir(df1_teste$sobremesa, df1_teste$predito)

```

Destacar no texto qual tipo de erro mais ocorreu!

```{r, render=lemon_print}
#as.data.frame(conf.m$overall)
#as.data.frame(conf.m$byClass)

```

## Análise de diagnóstico dos resíduos

```{r, warning=FALSE}
env = hnp::hnp(modelo, print.on = T, plot.sim = F)

total = paste0("Total de pontos: ", env$total,
            "\nPontos fora do envelope: ", env$out,
            " (", round(env$out/env$total, 4)*100, "%)")
plot(env, xlab="Quantis teóricos", ylab="Resíduos")
text(x=1, y=4.3, total)



```

```{r}
#par(bg='gray')
par(mfrow=c(2,2))

plot(modelo)

cat("\nOs outliers foram:\n")
modelo[["data"]][c(4513, 9610, 8554), ]

#Box.test(modelo$residuals, type="Ljung")

car::durbinWatsonTest(modelo)

```

```{r}
resid_pearson = residuals(modelo, "pearson")
resid_padron = rstandard(modelo)
alavanca = hatvalues(modelo)

#par(bg='gray')
par(mfrow=c(1,2))

plot(resid_pearson, ylab="Resíduo de Pearson", xlab = "", ylim=c(-1,1)*8)
abline(h=0, col='red')

plot(resid_padron, ylab="Resíduos padronizados", xlab = "")
abline(h=c(-2,2), col='red')

par(mfrow=c(1,1))
plot(alavanca, ylab="Alavancagem", xlab="")
abline(h = (2*ncol(df1_teste)/length(df1_teste$sobremesa)), col="red")

```

## Parte final (teste com outros tamanhos amostrais)

Para esse conjunto de dados, realmente é necessário utilizar todos dados selecionados para ajustar um modelo satisfatório?

Tabulação das seguintes métricas para o mesmo modelo (mesmas variáveis explicativas): acurácia, precisão, sensibilidade, AIC, BIC.
Deve conter qual o modelo final; qual o tamanho amostral do conjunto de treino e do de teste (proporção 70-30 sempre).

```{r, warning=FALSE}
tabelado = function(vetor)
{
  df = data.frame(tamanho = 0,
                    evento.interesse = 0,
                    acuracidade = 0,
                    sensibilidade = 0,
                    especif = 0,
                    hnp.fora = 0)
  
  for(N in vetor){
    
    treino = dsel[aux1[1:round(N*.7)], ]
    teste = dsel[aux1[round(N*.7+1):N], ]
    cat(dim(treino)[1], dim(teste)[1])
    modelo = glm(sobremesa ~ nota + calorias + proteina + gordura + sodio,
               family = binomial(link = 'logit'), data = treino)
    
    # predição
    preditos = predict(object = modelo, newdata = teste, type = "response")
    teste$prob_pred <- preditos
    
    # envelope simulado
    set.seed(2024)
    env = hnp::hnp(modelo, print.on = T, plot.sim = F)
    
    # curva ROC
    curva_roc = pROC::roc(teste$sobremesa, teste$prob_pred)
    optimal_coords <- pROC::coords(curva_roc, "best", ret = c("threshold",
                                                            "sensitivity",
                                                            "specificity"))
  
    # matriz de confusão
    teste$predito <- ifelse(teste$prob_pred < optimal_coords$threshold, 0, 1)
  
    conf.m = caret::confusionMatrix(data = as.factor(teste$predito),
                           reference = as.factor(teste$sobremesa))

    # tabela
    novalinha = data.frame(tamanho = N,
                    evento.interesse = sum(teste$sobremesa)/length(teste$sobremesa),
                    acuracidade = conf.m$overall[[1]],
                    sensibilidade = conf.m$byClass[[1]],
                    especif = conf.m$byClass[[2]],
                    hnp.fora = env$out/env$total)
    
    df <- rbind(df, novalinha)
  }
  df <- df[-1, ]
  colnames(df) <- c("Tamanho", "Evento de interesse", "Acuracidade",
                    "Sensibilidade", "Especificidade", "Pontos fora (envelope)")
  
  return(df)
}

```


```{r}
tabelado_mult = function(vetor, iter)
{
  df = data.frame(tamanho = 0,
                    evento.interesse = 0,
                    acuracidade = 0,
                    sensibilidade = 0,
                    especif = 0,
                    precisao = 0,
                    hnp.fora = 0)
  
  set.seed(2024)
  
  for(N in vetor){
    resultados <- as.data.frame((matrix(NA, ncol=7, byrow=T)))
    for(i in 1:iter){
      
      # Para cada iteração um novo sorteio!
      aux1 = sample(c(1:length(dsel[, 1])))
  
      treino = dsel[aux1[1:round(N*.7)], ]
      teste = dsel[aux1[round(N*.7+1):N], ]
      #cat(treino$titulo[1:5], teste$titulo[1:5], "\n")
      modelo = glm(sobremesa ~ nota + calorias + proteina + gordura + sodio,
                 family = binomial(link = 'logit'), data = treino)
      
      # predição
      preditos = predict(object = modelo, newdata = teste, type = "response")
      teste$prob_pred <- preditos
      
      # envelope simulado
      env = hnp::hnp(modelo, print.on = T, plot.sim = F)
      
      # curva ROC
      curva_roc = pROC::roc(teste$sobremesa, teste$prob_pred)
      optimal_coords <- pROC::coords(curva_roc, "best", ret = c("threshold",
                                                              "sensitivity",
                                                              "specificity"))
    
      # matriz de confusão
      teste$predito <- ifelse(teste$prob_pred < optimal_coords$threshold, 0, 1)
    
      x = confundir(teste$sobremesa, teste$predito)
  
      # tabela
      novalinha = data.frame(V1 = N,
                      V2 = x$Evento.de.interesse,
                      V3 = x$Acuracidade,
                      V4 = x$Sensibilidade,
                      V5 = x$Especificidade,
                      V6 = x$Precisao,                      
                      V7 = env$out/env$total)
  
    resultados <- rbind(resultados, novalinha)
    }
    
    resultados <- na.omit(resultados)

    df = add_row(df, tamanho = mean(resultados$V1),
                    evento.interesse = mean(resultados$V2),
                    acuracidade = mean(resultados$V3),
                    sensibilidade = mean(resultados$V4),
                    especif = mean(resultados$V5),
                    precisao = mean(resultados$V6),
                    hnp.fora = mean(resultados$V7))
    }
    
  print(resultados)
  
  df <- df[-1, ]
  
  colnames(df) <- c("Tamanho", "Evento de interesse", "Acuracidade",
                    "Sensibilidade", "Especificidade", "Precisão",
                    "Pontos fora (envelope)")
  
  return(df)
  }
  

```

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
N = c(200, 400, 800, 2000, 4000, 10000)
resp = tabelado_mult(N, 100)

```

\newpage

```{r, render=lemon_print}

#write.csv(resp, file=saida)

resp = read.csv(saida)

resp = resp[, -1]

resp[, 2:7] <- round(resp[, 2:7], 6)*100

colnames(resp) <- c("N", "Evento (Y=1)", "Acurac.",
                    "Sens.", "Espec.", "Prec.", "Fora do env.")

resp

```


```{r, warning=FALSE, message=FALSE}
#tabelado(N)

```

```{r}
pb <- progress::progress_bar$new(
format = " calculando [:bar] :percent  tempo estimado: :eta",
total = 100, clear = FALSE, width= 60)
for (i in 1:100) {
pb$tick()
Sys.sleep(1 / 100)
}

```


## Referências

https://rpubs.com/mpfoley73/527573

https://www.kaggle.com/code/rtatman/regression-challenge-day-1

https://www.kaggle.com/code/rtatman/datasets-for-regression-analysis#Poisson-regression-(predicting-a-count-value)

https://www.kaggle.com/datasets/hugodarwood/epirecipes?resource=download


